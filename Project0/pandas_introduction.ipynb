{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Introduction \n",
    "Material referenced from Data 100, EEP 153 Spring 2023 Materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Goals:\n",
    "1. DataFrame & Series\n",
    "2. Slicing, iloc, loc\n",
    "3. Groupby\n",
    "4. Joins & Merges\n",
    "5. Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro Pandas DataFrames\n",
    "Pandas: Slicing & Indexing\n",
    "Pandas: Aggregation\n",
    "Python Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a data analysis library/toolkit for Python. It is widely used in data science because it allows us to create objects called DataFrames that are just like tables and can be manipulated as such. These are basically rectangular arrays of data, with names for rows and columns, rather like a spreadsheet. In fact, one important thing one can do with DataFrames is to import data from spreadsheets. They also integrate well with NumPy arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [dataframe](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) is a table in which each column has a type; there is an index over the columns (typically string labels) and an index over the rows (typically ordinal numbers).\n",
    "\n",
    "The [docs](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) for the pandas `DataFrame` class  provide at least two syntaxes to create a data frame.\n",
    "\n",
    "Let's make our own DataFrame and learn to manipulate it. One way to make a DataFrame is to use pd.DataFrame and input the data manually, like below. Later, we'll show how to import Google Sheets or Excel files into DataFrames, which will be much more applicable in projects and assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a data frame by specifying the columns and values using a dictionary as shown below. \n",
    "\n",
    "The keys of the dictionary are the column names, and the values of the dictionary are lists containing the row entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe = pd.DataFrame(\n",
    "    data={'ingredient': ['eggs', 'brown sugar', 'flour', 'vanilla', 'sugar', 'chocolate chips', 'baking soda', 'butter'],\n",
    "          'price': [3.5, 2.99, 5.49, 5, 3.99, 2.99, 4.50, 5.00]\n",
    "          })\n",
    "my_recipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtain the dimensions of a dataframe by using the shape attribute `dataframe.shape` in a tuple with (# of rows, # of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert the entire dataframe into a two-dimensional numpy array using the `dataframe.values` for a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a column to a dataframe very easily with `d['new column name']` = ... and assign a list or array of values to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe['need to buy'] = [0,1,1,1,0,1,0,1]\n",
    "my_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add a column to `d` with `d.loc[:, 'new column name'] = ...`. This way to modify an existing dataframe is faster and therefore preferred over the assignment syntax above. The first parameter is for the rows and second is for columns. The `:` means change all rows and the `new column name` indicates the column you are modifying (or in this case, adding). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe.loc[:,'required for recipe'] = ['y', 'y', 'y','y', 'y', 'n', 'y', 'y']\n",
    "my_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `.drop()` method to [drop](https://pandas.pydata.org/pandasdocs/stable/generated/pandas.DataFrame.drop.html) to drop any columns you no longer need in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe = my_recipe.drop(columns = ['required for recipe'])\n",
    "my_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `.rename()` method to [rename](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html) dataframe columns. Let's rename all our columns to be capitalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipe = my_recipe.rename(columns = {'ingredient': 'Ingredient', 'price': 'Price', 'need to buy':'Need to Buy'})\n",
    "my_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beisdes DataFrames, another useful Pandas structure is a [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html). A Series is a type of list in Pandas which can take integer values, string values, and more that returns a Series object. It is different from a DataFrame, which is made up of multiple Series, while a single Series can only contain one list. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_series = my_recipe['Ingredient']\n",
    "ingredient_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a Series is an object that is a list of values indexed from 0 to n. We can think of DataFrames as enhanced numpy 2D arrays (with better visual representation), and Series as enhanced numpy 1D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ingredient_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: Slicing and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to look at some school census data from https://ww2.amstat.org/censusatschool/. Pandas has the capability of reading data from different file formats (such as .csv, .xlsx, Google Sheets), so we can easily import any data that we download into the same folder as our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_sample_CA.csv')#, encoding= 'cp1252') #encoding parameter is not usually needed!\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the size of the dataset and see what we are working with in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.shape\n",
    "#We have 500 rows (500 individual student entries) and 60 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all 60 columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a specific column in the dataset using its column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "census['Data Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series have a nice function called [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) that returns a series listing the number of times each value appears in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['Data Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, we need to slice the dataframe to obtain smaller subsets of the table to analyze. This can be accomplished by using label (loc) or index (iloc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Using Label/Index (using loc)\n",
    "\n",
    "**Column Selection** \n",
    "\n",
    "To select a column of a `DataFrame` by column label, the safest and fastest way is to use the `.loc` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html). General usage of `.loc` looks like `df.loc[rowname, colname]`. (Reminder that the colon `:` means \"everything.\")  For example, if we want the `color` column of the `ex` data frame, we would use: `ex.loc[:, 'color']`\n",
    "\n",
    "- You can also slice across columns. For example, `census.loc[:, 'Gender':]` would select the column `Gender` and all columns after `Gender`.\n",
    "\n",
    "**Row Selection**\n",
    "\n",
    "Similarly, if we want to select a row by its label, we can use the same `.loc` method. In this case, the \"label\" of each row refers to the index (ie. primary key) of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census.loc[1:5, 'Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a single column, you can just pass in that column name and it will return a Series. If you need multiple columns or to return a dataframe, you must put the column parameneter in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.loc[1:5, ['Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.loc[1:5, ['Gender', 'Height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection using Integer location (using iloc)\n",
    "\n",
    "Pandas has another feature `iloc[]` which lets you slice the dataframe by row position and column position instead of by row index and column label (which is the case for `loc[]`). This is really the main difference between the 2 functions and it is **important** that you remember the difference and why you might want to use one over the other. In addition, with `iloc[]`, the end index is NOT included, like with normal Python slicing.\n",
    "\n",
    "Note that when you sort or rearrange the dataframe, the *position* of a row is not necessarily equal to the *index* of a row. For example, the first row is not necessarily the row associated with index 1. This distinction is important in understanding the different between `loc[]` and `iloc[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_census = census.sort_values(by = ['Class Grade'])\n",
    "sorted_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how we would get the 2nd, 3rd, and 4th rows with only the `Gender` column of the `census` dataframe using both `iloc[]` and `loc[]`. Observe the difference, especially after sorting by `ClassGrade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_census.iloc[1:4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_census.iloc[1:4, :6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can change the index of a dataframe using the [set_index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_index = census.set_index('Gender')\n",
    "change_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with boolean arrays\n",
    "\n",
    "Filtering is the process of removing unwanted material.  To clean data, you will have to filter your data at some point: whether it be for clearing up cases with missing values, taking out outliers, or for analyzing subgroups of your data set.  Note that compound expressions have to be grouped with parentheses. Example usage looks like `df[df['column name'] < 5]]`.\n",
    "\n",
    "Some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning \n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    ">=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the rows of the Dataframe where Data Year = 2020\n",
    "census2020 = census[census['Data Year'] == 2020]\n",
    "census2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also put multiple conditions together. Any time you use `p & q` to filter the dataframe, make sure to use `df[df[(p) & (q)]]` or `df.loc[df[(p) & (q)]])`. That is, make sure to wrap conditions with parentheses.\n",
    "\n",
    "**Remember** that both slicing and `loc` will achieve the same result, it is just that `loc` is typically faster in production. You are free to use whichever one you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the rows where DataYear = 2020 and Female\n",
    "census_2020_f = census[(census['Data Year'] == 2020) & (census['Gender'] == 'Female')]\n",
    "census_2020_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_q = census.loc[:, ['Age', 'Class Grade', 'Languages spoken']]\n",
    "census_q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Aggregation\n",
    "When you first come across a large dataset, the best way to get a sense of it is to get summary statistics. The [aggregate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.aggregate.html) allows you to do this. Using `df.aggregate()` directly on the whole dataframe will apply the aggregation functions on the entire dataframe at once.\n",
    "\n",
    "Some common built-in Pandas aggregations are provided below:\n",
    "\n",
    "Aggregation | Description \n",
    "------ | ---------- \n",
    "`count()`   | Total number of items\n",
    "`first()`   | First and last item\n",
    "`mean(), median()`   | Mean and median\n",
    "`min(), max()`   | Minimum and maximum\n",
    "`std(), var()`   | Standard deviation and variance\n",
    "`mad()`   | Mean absolute deviation\n",
    "`prod()`   | Product of all items\n",
    "`sum()`   | Sum of all items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_q.aggregate(['min', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#You can also specify different aggregations for each column\n",
    "census_q.aggregate({'Age': ['std', 'mean'], 'Class Grade': ['median', 'var'], 'Languages spoken': ['max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple aggregations can give you a flavor of your dataset, but often we would prefer to aggregate conditionally on some label or index: this is implemented in the so-called [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) operation. When you first apply `groupby()` to a dataframe, it returns a groupby object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.groupby('Class Grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, you can specify how you want to aggregate the rows of the Groupby object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.groupby('Class Grade').agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the agggregation is then applied to each column that the aggregation function can be used on. `sum` can only be applied on integers and floats, so it omits and columns that have other datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census.groupby('Class Grade').agg(list).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring your dataset, it's important to be able to represent it visually. `matplotlib.pyplot` is a library that allows you to make basic visualizations. Later in the course, we will explore more advanced libraries to create more complex visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age and foot length for all males in the census dataframe\n",
    "census_af = census[census['Gender'] == 'Male'].loc[:,['Age', 'Right foot length']]\n",
    "census_af['Right foot length'] = pd.to_numeric(census_af['Right foot length'])\n",
    "census_af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a plot directly from the dataframe with the [plt.plot](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.plot.html) by specifying the columns that are to be used for the x and y axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_af.plot(x = 'Age', y = 'Right foot length', kind = 'scatter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
